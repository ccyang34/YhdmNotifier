#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†æå¸ˆ
æ•´åˆæ–°æµªè´¢ç»è¡Œä¸šæ•°æ®è·å–ã€æ™ºèƒ½åˆ†æå’ŒAIæ·±åº¦è§£è¯»åŠŸèƒ½
ç»“åˆå¤šæ—¶é—´ç»´åº¦èµ„é‡‘æµå‘åˆ†æ

Author: AI Assistant
Date: 2024-12-02
"""

# =============================================================================
# å¯¼å…¥æ¨¡å—
# =============================================================================

# æ ‡å‡†åº“å¯¼å…¥
import os
import time
import warnings
import json
from datetime import datetime
from io import StringIO

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import requests
import pandas as pd
import numpy as np
import pytz


# =============================================================================
# é…ç½®å¸¸é‡
# =============================================================================

# ---------------- DeepSeek API é…ç½® ----------------
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-063857d175bd48038684520e7b6ec934")
DEEPSEEK_BASE_URL = "https://api.deepseek.com"
MODEL_NAME = "deepseek-chat"

# ---------------- æ¨é€é…ç½® (WxPusher) ----------------
WXPUSHER_APP_TOKEN = os.getenv("WXPUSHER_APP_TOKEN", "AT_UHus2F8p0yjnG6XvGEDzdCp5GkwvLdkc")
WXPUSHER_TOPIC_IDS = [42353]  # ç›®æ ‡ä¸»é¢˜ ID åˆ—è¡¨42540å¤‡ç”¨
WXPUSHER_URL = "https://wxpusher.zjiecode.com/api/send/message"

# ---------------- æ—¶åŒºé…ç½® ----------------
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def get_beijing_time():
    """
    è·å–åŒ—äº¬æ—¶é—´
    
    Returns:
        datetime: åŒ—äº¬æ—¶é—´å¯¹è±¡
    """
    return datetime.now(BEIJING_TZ)

# =============================================================================
# æ•°æ®è·å–æ¨¡å—
# =============================================================================

class DataFetcher:
    """
    æ•°æ®è·å–ç±» - ä¸“æ³¨äºè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®è·å–
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        self.base_url = "https://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/MoneyFlow.ssl_bkzjlxt"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36 Edg/142.0.0.0',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'Referer': 'https://vip.stock.finance.sina.com.cn/moneyflow/',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        # åˆ›å»ºsessionä»¥é¿å…ä»£ç†é—®é¢˜
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.trust_env = False
    
    def fetch_industry_flow_data(self, page=1, num=20, sort='cate_id', asc=1, fenlei=2):
        """
        è·å–è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®
        
        Args:
            page: é¡µç ï¼Œé»˜è®¤1
            num: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤20
            sort: æ’åºå­—æ®µï¼Œé»˜è®¤cate_idï¼ˆè¡Œä¸šä»£ç ï¼‰
            asc: æ’åºæ–¹å‘ï¼Œ0é™åºï¼Œ1å‡åºï¼Œé»˜è®¤1
            fenlei: åˆ†ç±»ï¼Œ2è¡¨ç¤ºè·å–è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®
            
        Returns:
            dict: è¿”å›çš„è¡Œä¸šJSONæ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        url = self.base_url
        params = {
            'page': page,
            'num': num,
            'sort': sort,
            'asc': asc,
            'fenlei': fenlei
        }
        
        try:
            print(f"æ­£åœ¨è·å–ç¬¬{page}é¡µè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®...")
            response = self.session.get(url, params=params, timeout=15)
            response.raise_for_status()
            response.encoding = 'gbk'  # æ–°æµªè´¢ç»ä½¿ç”¨GBKç¼–ç 
            
            # è§£æJSONæ•°æ®
            content = response.text.strip()
            if content.startswith('[') and content.endswith(']'):
                data = json.loads(content)
            else:
                # å¤„ç†å¯èƒ½çš„JSONPæ ¼å¼
                start = content.find('(') + 1
                end = content.rfind(')')
                if start > 0 and end > start:
                    data = json.loads(content[start:end])
                else:
                    data = json.loads(content)
            
            print(f"ç¬¬{page}é¡µè·å–æˆåŠŸï¼Œå…±{len(data)}æ¡æ•°æ®")
            return data
            
        except requests.exceptions.RequestException as e:
            print(f"è·å–ç¬¬{page}é¡µæ•°æ®å‡ºé”™: {str(e)}")
            return None
        except json.JSONDecodeError as e:
            print(f"è§£æç¬¬{page}é¡µJSONæ•°æ®å‡ºé”™: {str(e)}")
            return None
        except Exception as e:
            print(f"ç¬¬{page}é¡µæ•°æ®å¤„ç†å‡ºé”™: {str(e)}")
            return None
    
    def parse_industry_flow_data(self, raw_data):
        """
        è§£æè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®
        
        Args:
            raw_data: åŸå§‹è¡Œä¸šJSONæ•°æ®
            
        Returns:
            list: è§£æåçš„è¡Œä¸šæ•°æ®åˆ—è¡¨
        """
        if not raw_data:
            return []
        
        parsed_data = []
        for item in raw_data:
            try:
                # è§£æè¡Œä¸šæ•°æ®å­—æ®µï¼Œé€‚é…å¤šæ—¶é—´ç»´åº¦
                parsed_item = {
                    'è¡Œä¸šä»£ç ': item.get('category', ''),
                    'è¡Œä¸šåç§°': item.get('name', ''),
                    '3æ—¥å‡€æµå…¥': float(item.get('netamount_3', 0)),
                    '3æ—¥å‡€æµå…¥å æ¯”': float(item.get('ratioamount_3', 0)),
                    '3æ—¥å¹³å‡æ¶¨è·Œå¹…': float(item.get('avg_changeratio_3', 0)),
                    '3æ—¥æµå…¥æµå‡ºæ¯”': float(item.get('r0x_ratio_3', 0)),
                    '5æ—¥å‡€æµå…¥': float(item.get('netamount_5', 0)),
                    '5æ—¥å‡€æµå…¥å æ¯”': float(item.get('ratioamount_5', 0)),
                    '5æ—¥å¹³å‡æ¶¨è·Œå¹…': float(item.get('avg_changeratio_5', 0)),
                    '5æ—¥æµå…¥æµå‡ºæ¯”': float(item.get('r0x_ratio_5', 0)),
                    '10æ—¥å‡€æµå…¥': float(item.get('netamount_10', 0)),
                    '10æ—¥å‡€æµå…¥å æ¯”': float(item.get('ratioamount_10', 0)),
                    '10æ—¥å¹³å‡æ¶¨è·Œå¹…': float(item.get('avg_changeratio_10', 0)),
                    '10æ—¥æµå…¥æµå‡ºæ¯”': float(item.get('r0x_ratio_10', 0)),
                    'æ•°æ®æ›´æ–°æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                parsed_data.append(parsed_item)
                
            except (ValueError, TypeError) as e:
                print(f"è§£ææ•°æ®é¡¹æ—¶å‡ºé”™: {str(e)}, æ•°æ®: {item}")
                continue
        
        return parsed_data
    
    def collect_batch_data(self, total_pages=8, page_size=20):
        """
        æ‰¹é‡è·å–å¤šé¡µè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®
        
        Args:
            total_pages: æ€»é¡µæ•°ï¼Œé»˜è®¤8é¡µï¼ˆå®Œæ•´æ•°æ®ï¼‰
            page_size: æ¯é¡µå¤§å°ï¼Œé»˜è®¤20æ¡
            
        Returns:
            list: åˆå¹¶åçš„æ‰€æœ‰è¡Œä¸šæ•°æ®
        """
        all_data = []
        
        print(f"=== å¼€å§‹æ‰¹é‡è·å–è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ® ===")
        print(f"ç›®æ ‡: è·å–{total_pages}é¡µè¡Œä¸šæ•°æ®ï¼Œæ¯é¡µ{page_size}æ¡")
        
        for page in range(1, total_pages + 1):
            print(f"\n--- è·å–ç¬¬{page}é¡µæ•°æ® ---")
            
            # è·å–åŸå§‹æ•°æ®
            raw_data = self.fetch_industry_flow_data(page=page, num=page_size)
            if raw_data:
                # è§£ææ•°æ®
                parsed_data = self.parse_industry_flow_data(raw_data)
                if parsed_data:
                    all_data.extend(parsed_data)
                    print(f"ç¬¬{page}é¡µè§£ææˆåŠŸï¼Œè·å¾—{len(parsed_data)}æ¡æ•°æ®")
                else:
                    print(f"ç¬¬{page}é¡µæ•°æ®è§£æå¤±è´¥")
            else:
                print(f"ç¬¬{page}é¡µæ•°æ®è·å–å¤±è´¥")
            
            # æ·»åŠ é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if page < total_pages:
                print("ç­‰å¾…1ç§’...")
                time.sleep(1)
        
        print(f"\n=== æ‰¹é‡è·å–å®Œæˆ ===")
        print(f"æ€»è®¡è·å¾— {len(all_data)} æ¡æ•°æ®")
        
        return all_data

# =============================================================================
# æ•°æ®åˆ†ææ¨¡å—
# =============================================================================

class DataAnalyzer:
    """
    æ•°æ®åˆ†æç±» - ä¸“æ³¨äºè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®åˆ†æ
    """
    
    @staticmethod
    def save_to_csv(data, filename=None):
        """
        ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filename: æ–‡ä»¶åï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶åï¼Œå¤±è´¥è¿”å›None
        """
        if not data:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"AIè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®_{timestamp}.csv"
        
        try:
            df = pd.DataFrame(data)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
            return filename
        except Exception as e:
            print(f"ä¿å­˜CSVæ–‡ä»¶å‡ºé”™: {str(e)}")
            return None
    
    @staticmethod
    def get_industry_summary(data):
        """
        è·å–è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ¦‚å†µç»Ÿè®¡
        
        Args:
            data: è¡Œä¸šæ•°æ®åˆ—è¡¨
            
        Returns:
            dict: æ±‡æ€»ç»Ÿè®¡æ•°æ®
        """
        if not data:
            return {}
        
        df = pd.DataFrame(data)
        
        # åŸºç¡€ç»Ÿè®¡
        total_industries = len(df)
        positive_3d = len(df[df['3æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        positive_5d = len(df[df['5æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        positive_10d = len(df[df['10æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        
        # å‡€æµå…¥ç»Ÿè®¡
        total_inflow_3d = df['3æ—¥å‡€æµå…¥'].sum()
        total_inflow_5d = df['5æ—¥å‡€æµå…¥'].sum()
        total_inflow_10d = df['10æ—¥å‡€æµå…¥'].sum()
        
        # æµå…¥æµå‡ºæ¯”ç»Ÿè®¡
        avg_ratio_3d = df['3æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        avg_ratio_5d = df['5æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        avg_ratio_10d = df['10æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        
        # å‡€æµå…¥å‰10ï¼ˆå¤šæ—¶é—´ç»´åº¦ï¼‰
        top_inflow_3d = df.nlargest(10, '3æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '3æ—¥å‡€æµå…¥', '3æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        top_inflow_5d = df.nlargest(10, '5æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '5æ—¥å‡€æµå…¥', '5æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        top_inflow_10d = df.nlargest(10, '10æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '10æ—¥å‡€æµå…¥', '10æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        
        summary = {
            'total_industries': total_industries,
            'positive_3d_count': positive_3d,
            'positive_5d_count': positive_5d,
            'positive_10d_count': positive_10d,
            'total_inflow_3d_billion': total_inflow_3d / 1e8,
            'total_inflow_5d_billion': total_inflow_5d / 1e8,
            'total_inflow_10d_billion': total_inflow_10d / 1e8,
            'avg_ratio_3d': avg_ratio_3d,
            'avg_ratio_5d': avg_ratio_5d,
            'avg_ratio_10d': avg_ratio_10d,
            'top_inflow_3d': top_inflow_3d,
            'top_inflow_5d': top_inflow_5d,
            'top_inflow_10d': top_inflow_10d
        }
        
        return summary
    
    @staticmethod
    def analyze_market_structure(data):
        """
        å¯¹è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®è¿›è¡Œç»“æ„åŒ–åˆ†æ
        é‡ç‚¹åˆ†æå¤šæ—¶é—´ç»´åº¦çš„è¡Œä¸šè½®åŠ¨å’Œèµ„é‡‘è¶‹åŠ¿
        
        Args:
            data: è¡Œä¸šæ•°æ®åˆ—è¡¨
            
        Returns:
            dict: ç»“æ„åŒ–åˆ†æç»“æœ
        """
        if not data:
            return None
        
        df = pd.DataFrame(data)
        
        analysis_result = {
            'summary': {},
            'flow_trends': {},
            'sector_rotation': {},
            'risk_industries': {},
            'hot_industries': {}
        }
        
        # åŸºç¡€ç»Ÿè®¡
        total_industries = len(df)
        positive_3d = len(df[df['3æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        positive_5d = len(df[df['5æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        positive_10d = len(df[df['10æ—¥å¹³å‡æ¶¨è·Œå¹…'] > 0])
        
        # å‡€æµå…¥ç»Ÿè®¡
        total_inflow_3d = df['3æ—¥å‡€æµå…¥'].sum()
        total_inflow_5d = df['5æ—¥å‡€æµå…¥'].sum()
        total_inflow_10d = df['10æ—¥å‡€æµå…¥'].sum()
        
        # æµå…¥æµå‡ºæ¯”ç»Ÿè®¡
        avg_ratio_3d = df['3æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        avg_ratio_5d = df['5æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        avg_ratio_10d = df['10æ—¥æµå…¥æµå‡ºæ¯”'].mean()
        
        # åŸºç¡€åˆ†ææ±‡æ€»
        analysis_result['summary'] = {
            'total_industries': total_industries,
            'positive_3d_count': positive_3d,
            'positive_5d_count': positive_5d,
            'positive_10d_count': positive_10d,
            'total_inflow_3d_billion': total_inflow_3d / 1e8,
            'total_inflow_5d_billion': total_inflow_5d / 1e8,
            'total_inflow_10d_billion': total_inflow_10d / 1e8,
            'avg_ratio_3d': avg_ratio_3d,
            'avg_ratio_5d': avg_ratio_5d,
            'avg_ratio_10d': avg_ratio_10d
        }
        
        # èµ„é‡‘æµå‘è¶‹åŠ¿åˆ†æ
        big_inflow_3d = df[df['3æ—¥å‡€æµå…¥'] > 5e7]  # 3æ—¥å‡€æµå…¥è¶…5000ä¸‡
        big_inflow_5d = df[df['5æ—¥å‡€æµå…¥'] > 5e7]  # 5æ—¥å‡€æµå…¥è¶…5000ä¸‡
        big_inflow_10d = df[df['10æ—¥å‡€æµå…¥'] > 5e7]  # 10æ—¥å‡€æµå…¥è¶…5000ä¸‡
        
        analysis_result['flow_trends'] = {
            'big_inflow_3d_count': len(big_inflow_3d),
            'big_inflow_5d_count': len(big_inflow_5d),
            'big_inflow_10d_count': len(big_inflow_10d),
            'top_inflow_3d': big_inflow_3d.nlargest(10, '3æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '3æ—¥å‡€æµå…¥', '3æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records'),
            'top_inflow_5d': big_inflow_5d.nlargest(10, '5æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '5æ—¥å‡€æµå…¥', '5æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records'),
            'top_inflow_10d': big_inflow_10d.nlargest(10, '10æ—¥å‡€æµå…¥')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '10æ—¥å‡€æµå…¥', '10æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        }
        
        # è¡Œä¸šè½®åŠ¨åˆ†æ
        # è®¡ç®—è¡Œä¸šå¼ºåº¦æŒ‡æ ‡
        df['3æ—¥å¼ºåº¦'] = df['3æ—¥å‡€æµå…¥'] * df['3æ—¥æµå…¥æµå‡ºæ¯”'] * (1 + df['3æ—¥å¹³å‡æ¶¨è·Œå¹…'])
        df['5æ—¥å¼ºåº¦'] = df['5æ—¥å‡€æµå…¥'] * df['5æ—¥æµå…¥æµå‡ºæ¯”'] * (1 + df['5æ—¥å¹³å‡æ¶¨è·Œå¹…'])
        df['10æ—¥å¼ºåº¦'] = df['10æ—¥å‡€æµå…¥'] * df['10æ—¥æµå…¥æµå‡ºæ¯”'] * (1 + df['10æ—¥å¹³å‡æ¶¨è·Œå¹…'])
        
        # çŸ­æœŸå¼ºåŠ¿è¡Œä¸šï¼ˆ3æ—¥ï¼‰
        strong_3d = df.nlargest(15, '3æ—¥å¼ºåº¦')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '3æ—¥å¼ºåº¦', '3æ—¥å‡€æµå…¥', '3æ—¥æµå…¥æµå‡ºæ¯”', '3æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        
        # ä¸­æœŸå¼ºåŠ¿è¡Œä¸šï¼ˆ5æ—¥ï¼‰
        strong_5d = df.nlargest(15, '5æ—¥å¼ºåº¦')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '5æ—¥å¼ºåº¦', '5æ—¥å‡€æµå…¥', '5æ—¥æµå…¥æµå‡ºæ¯”', '5æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        
        # é•¿æœŸå¼ºåŠ¿è¡Œä¸šï¼ˆ10æ—¥ï¼‰
        strong_10d = df.nlargest(15, '10æ—¥å¼ºåº¦')[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '10æ—¥å¼ºåº¦', '10æ—¥å‡€æµå…¥', '10æ—¥æµå…¥æµå‡ºæ¯”', '10æ—¥å¹³å‡æ¶¨è·Œå¹…']].to_dict('records')
        
        analysis_result['sector_rotation'] = {
            'strong_3d': strong_3d,
            'strong_5d': strong_5d,
            'strong_10d': strong_10d
        }
        
        # é£é™©è¡Œä¸šè¯†åˆ«
        # å¤§é¢æµå‡ºè¡Œä¸š
        big_outflow_3d = df[df['3æ—¥å‡€æµå…¥'] < -5e7]  # 3æ—¥å‡€æµå‡ºè¶…5000ä¸‡
        big_outflow_5d = df[df['5æ—¥å‡€æµå…¥'] < -5e7]  # 5æ—¥å‡€æµå‡ºè¶…5000ä¸‡
        big_outflow_10d = df[df['10æ—¥å‡€æµå…¥'] < -5e7]  # 10æ—¥å‡€æµå‡ºè¶…5000ä¸‡
        
        # è´Ÿæµå…¥æµå‡ºæ¯”è¡Œä¸šï¼ˆæµå‡ºå¤§äºæµå…¥ï¼‰
        negative_ratio_3d = df[df['3æ—¥æµå…¥æµå‡ºæ¯”'] < 0]
        negative_ratio_5d = df[df['5æ—¥æµå…¥æµå‡ºæ¯”'] < 0]
        negative_ratio_10d = df[df['10æ—¥æµå…¥æµå‡ºæ¯”'] < 0]
        
        analysis_result['risk_industries'] = {
            'big_outflow_3d_count': len(big_outflow_3d),
            'big_outflow_5d_count': len(big_outflow_5d),
            'big_outflow_10d_count': len(big_outflow_10d),
            'negative_ratio_3d_count': len(negative_ratio_3d),
            'negative_ratio_5d_count': len(negative_ratio_5d),
            'negative_ratio_10d_count': len(negative_ratio_10d),
            'big_outflow_3d': big_outflow_3d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '3æ—¥å‡€æµå…¥', '3æ—¥æµå…¥æµå‡ºæ¯”']].to_dict('records'),
            'big_outflow_5d': big_outflow_5d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '5æ—¥å‡€æµå…¥', '5æ—¥æµå…¥æµå‡ºæ¯”']].to_dict('records'),
            'big_outflow_10d': big_outflow_10d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '10æ—¥å‡€æµå…¥', '10æ—¥æµå…¥æµå‡ºæ¯”']].to_dict('records')
        }
        
        # çƒ­é—¨è¡Œä¸šåˆ†æ
        # é«˜æµå…¥æµå‡ºæ¯”è¡Œä¸šï¼ˆèµ„é‡‘å…³æ³¨åº¦é«˜ï¼‰
        hot_ratio_3d = df[df['3æ—¥æµå…¥æµå‡ºæ¯”'] > 1.5]  # æµå…¥æ˜¯æµå‡ºçš„1.5å€ä»¥ä¸Š
        hot_ratio_5d = df[df['5æ—¥æµå…¥æµå‡ºæ¯”'] > 1.5]
        hot_ratio_10d = df[df['10æ—¥æµå…¥æµå‡ºæ¯”'] > 1.5]
        
        # å¤§é¢æµå…¥è¡Œä¸šï¼ˆèµ„é‡‘è§„æ¨¡å¤§ï¼‰
        hot_volume_3d = df[df['3æ—¥å‡€æµå…¥'] > 2e8]  # 3æ—¥å‡€æµå…¥è¶…2äº¿
        hot_volume_5d = df[df['5æ—¥å‡€æµå…¥'] > 2e8]  # 5æ—¥å‡€æµå…¥è¶…2äº¿
        hot_volume_10d = df[df['10æ—¥å‡€æµå…¥'] > 2e8]  # 10æ—¥å‡€æµå…¥è¶…2äº¿
        
        analysis_result['hot_industries'] = {
            'hot_ratio_3d_count': len(hot_ratio_3d),
            'hot_ratio_5d_count': len(hot_ratio_5d),
            'hot_ratio_10d_count': len(hot_ratio_10d),
            'hot_volume_3d_count': len(hot_volume_3d),
            'hot_volume_5d_count': len(hot_volume_5d),
            'hot_volume_10d_count': len(hot_volume_10d),
            'hot_ratio_3d': hot_ratio_3d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '3æ—¥æµå…¥æµå‡ºæ¯”', '3æ—¥å‡€æµå…¥']].to_dict('records'),
            'hot_ratio_5d': hot_ratio_5d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '5æ—¥æµå…¥æµå‡ºæ¯”', '5æ—¥å‡€æµå…¥']].to_dict('records'),
            'hot_ratio_10d': hot_ratio_10d[['è¡Œä¸šä»£ç ', 'è¡Œä¸šåç§°', '10æ—¥æµå…¥æµå‡ºæ¯”', '10æ—¥å‡€æµå…¥']].to_dict('records')
        }
        
        return analysis_result

# =============================================================================
# AIåˆ†ææ¨¡å—
# =============================================================================

class AIAnalyzer:
    """
    AIåˆ†æç±» - ä¸“æ³¨äºè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIæ™ºèƒ½åˆ†æ
    """
    
    @staticmethod
    def prepare_ai_context(data, analysis_result):
        """
        ä¸ºAIå‡†å¤‡ç»“æ„åŒ–çš„åˆ†æä¸Šä¸‹æ–‡
        é‡ç‚¹çªå‡ºè¯ç›‘ä¼šè¡Œä¸šå¤šæ—¶é—´ç»´åº¦åˆ†æ
        
        Args:
            data: åŸå§‹æ•°æ®
            analysis_result: ç»“æ„åŒ–åˆ†æç»“æœ
            
        Returns:
            str: AIåˆ†æçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        if not analysis_result:
            return "æ•°æ®åˆ†æå¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"
        
        summary = analysis_result['summary']
        flow_trends = analysis_result['flow_trends']
        sector_rotation = analysis_result['sector_rotation']
        risk_industries = analysis_result['risk_industries']
        hot_industries = analysis_result['hot_industries']
        
        # æ„å»ºCSVå†…å®¹ç”¨äºAIåˆ†æ
        df = pd.DataFrame(data)
        csv_content = df.to_csv(index=False, encoding='utf-8-sig')
        
        context = f"""
===========================================
ğŸš€ è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ® - AIæ™ºèƒ½åˆ†æç‰ˆ
===========================================

ğŸ’° ã€å¸‚åœºæ•´ä½“æ¦‚å†µã€‘
- æ€»è¡Œä¸šæ•°: {summary['total_industries']}ä¸ª
- 3æ—¥ä¸Šæ¶¨è¡Œä¸š: {summary['positive_3d_count']}ä¸ª ({summary['positive_3d_count']/summary['total_industries']*100:.1f}%)
- 5æ—¥ä¸Šæ¶¨è¡Œä¸š: {summary['positive_5d_count']}ä¸ª ({summary['positive_5d_count']/summary['total_industries']*100:.1f}%)
- 10æ—¥ä¸Šæ¶¨è¡Œä¸š: {summary['positive_10d_count']}ä¸ª ({summary['positive_10d_count']/summary['total_industries']*100:.1f}%)
- 3æ—¥æ€»å‡€æµå…¥: {summary['total_inflow_3d_billion']:.2f}äº¿å…ƒ
- 5æ—¥æ€»å‡€æµå…¥: {summary['total_inflow_5d_billion']:.2f}äº¿å…ƒ
- 10æ—¥æ€»å‡€æµå…¥: {summary['total_inflow_10d_billion']:.2f}äº¿å…ƒ
- 3æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”: {summary['avg_ratio_3d']:.3f}
- 5æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”: {summary['avg_ratio_5d']:.3f}
- 10æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”: {summary['avg_ratio_10d']:.3f}

ğŸ† ã€çŸ­æœŸå¼ºåŠ¿è¡Œä¸šTOP10ï¼ˆ3æ—¥ï¼‰ã€‘"""
        
        # çŸ­æœŸå¼ºåŠ¿è¡Œä¸šåˆ†æ
        for i, industry in enumerate(sector_rotation['strong_3d'][:10], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']})
   ğŸ’° å‡€æµå…¥: {industry['3æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ
   ğŸ“ˆ å¹³å‡æ¶¨å¹…: {industry['3æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%
   ğŸ”„ æµå…¥æµå‡ºæ¯”: {industry['3æ—¥æµå…¥æµå‡ºæ¯”']:.2f}
   â­ å¼ºåº¦æŒ‡æ•°: {industry['3æ—¥å¼ºåº¦']/1e8:.2f}"""
        
        context += f"""

ğŸ¯ ã€ä¸­æœŸå¼ºåŠ¿è¡Œä¸šTOP10ï¼ˆ5æ—¥ï¼‰ã€‘"""
        for i, industry in enumerate(sector_rotation['strong_5d'][:10], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']})
   ğŸ’° å‡€æµå…¥: {industry['5æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ
   ğŸ“ˆ å¹³å‡æ¶¨å¹…: {industry['5æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%
   ğŸ”„ æµå…¥æµå‡ºæ¯”: {industry['5æ—¥æµå…¥æµå‡ºæ¯”']:.2f}
   â­ å¼ºåº¦æŒ‡æ•°: {industry['5æ—¥å¼ºåº¦']/1e8:.2f}"""
        
        context += f"""

ğŸš€ ã€é•¿æœŸå¼ºåŠ¿è¡Œä¸šTOP10ï¼ˆ10æ—¥ï¼‰ã€‘"""
        for i, industry in enumerate(sector_rotation['strong_10d'][:10], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']})
   ğŸ’° å‡€æµå…¥: {industry['10æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ
   ğŸ“ˆ å¹³å‡æ¶¨å¹…: {industry['10æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%
   ğŸ”„ æµå…¥æµå‡ºæ¯”: {industry['10æ—¥æµå…¥æµå‡ºæ¯”']:.2f}
   â­ å¼ºåº¦æŒ‡æ•°: {industry['10æ—¥å¼ºåº¦']/1e8:.2f}"""
        
        context += f"""

ğŸ”¥ ã€å¤§é¢æµå…¥è¡Œä¸šæ±‡æ€»ã€‘
ğŸ“Š 3æ—¥å¤§é¢æµå…¥ï¼ˆè¶…5000ä¸‡ï¼‰: {flow_trends['big_inflow_3d_count']}ä¸ª"""
        
        for i, industry in enumerate(flow_trends['top_inflow_3d'][:5], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - {industry['3æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ"""
        
        context += f"""
ğŸ“Š 5æ—¥å¤§é¢æµå…¥ï¼ˆè¶…5000ä¸‡ï¼‰: {flow_trends['big_inflow_5d_count']}ä¸ª"""
        for i, industry in enumerate(flow_trends['top_inflow_5d'][:5], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - {industry['5æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ"""
        
        context += f"""
ğŸ“Š 10æ—¥å¤§é¢æµå…¥ï¼ˆè¶…5000ä¸‡ï¼‰: {flow_trends['big_inflow_10d_count']}ä¸ª"""
        for i, industry in enumerate(flow_trends['top_inflow_10d'][:5], 1):
            context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - {industry['10æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ"""
        
        context += f"""

âš ï¸ ã€é£é™©è¡Œä¸šè­¦ç¤ºã€‘
ğŸ“‰ 3æ—¥å¤§é¢æµå‡ºï¼ˆè¶…5000ä¸‡ï¼‰: {risk_industries['big_outflow_3d_count']}ä¸ª"""
        if risk_industries['big_outflow_3d']:
            for i, industry in enumerate(risk_industries['big_outflow_3d'][:5], 1):
                context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - å‡€æµå‡º: {abs(industry['3æ—¥å‡€æµå…¥'])/1e8:.2f}äº¿å…ƒ"""
        else:
            context += "\næ— å¤§é¢æµå‡ºè¡Œä¸š"
        
        context += f"""
ğŸ“‰ 5æ—¥å¤§é¢æµå‡ºï¼ˆè¶…5000ä¸‡ï¼‰: {risk_industries['big_outflow_5d_count']}ä¸ª"""
        if risk_industries['big_outflow_5d']:
            for i, industry in enumerate(risk_industries['big_outflow_5d'][:5], 1):
                context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - å‡€æµå‡º: {abs(industry['5æ—¥å‡€æµå…¥'])/1e8:.2f}äº¿å…ƒ"""
        else:
            context += "\næ— å¤§é¢æµå‡ºè¡Œä¸š"
        
        context += f"""
ğŸ“‰ 10æ—¥å¤§é¢æµå‡ºï¼ˆè¶…5000ä¸‡ï¼‰: {risk_industries['big_outflow_10d_count']}ä¸ª"""
        if risk_industries['big_outflow_10d']:
            for i, industry in enumerate(risk_industries['big_outflow_10d'][:5], 1):
                context += f"""
{i}. {industry['è¡Œä¸šåç§°']}({industry['è¡Œä¸šä»£ç ']}) - å‡€æµå‡º: {abs(industry['10æ—¥å‡€æµå…¥'])/1e8:.2f}äº¿å…ƒ"""
        else:
            context += "\næ— å¤§é¢æµå‡ºè¡Œä¸š"
        
        context += f"""

ğŸŒŸ ã€è¡Œä¸šè½®åŠ¨æ´å¯Ÿã€‘
- çŸ­æœŸçƒ­ç‚¹: {sector_rotation['strong_3d'][0]['è¡Œä¸šåç§°'] if sector_rotation['strong_3d'] else 'æ— æ•°æ®'}
- ä¸­æœŸçƒ­ç‚¹: {sector_rotation['strong_5d'][0]['è¡Œä¸šåç§°'] if sector_rotation['strong_5d'] else 'æ— æ•°æ®'}
- é•¿æœŸçƒ­ç‚¹: {sector_rotation['strong_10d'][0]['è¡Œä¸šåç§°'] if sector_rotation['strong_10d'] else 'æ— æ•°æ®'}

===========================================
[å®Œæ•´CSVæ•°æ® - ç”¨äºæ·±åº¦åˆ†æ]
{csv_content}
===========================================
"""
        
        # ========== æ–°å¢ï¼šæ‰“å°AIä¸Šä¸‹æ–‡ä¿¡æ¯ ==========
        print("ğŸ“Š AIåˆ†æä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ:")
        print(f"   - ä¸Šä¸‹æ–‡æ€»å­—ç¬¦æ•°: {len(context):,} å­—ç¬¦")
        print(f"   - ä¸Šä¸‹æ–‡è¡Œæ•°: {len(context.split(chr(10)))} è¡Œ")
        print(f"   - è¡Œä¸šæ€»æ•°: {summary['total_industries']} ä¸ª")
        print(f"   - æ•°æ®è¦†ç›–: 3æ—¥/5æ—¥/10æ—¥ å¤šæ—¶é—´ç»´åº¦")
        print("="*50)
        print("ğŸ“‹ ä¸Šä¸‹æ–‡å†…å®¹é¢„è§ˆ:")
        print("-" * 50)
        print(context[:500] + "..." if len(context) > 500 else context)
        print("-" * 50)
        print("="*50)
        
        return context
    
    @staticmethod
    def call_ai_analysis(data, analysis_result):
        """
        è°ƒç”¨DeepSeekè¿›è¡Œè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†æ
        
        Args:
            data: åŸå§‹æ•°æ®
            analysis_result: ç»“æ„åŒ–åˆ†æç»“æœ
            
        Returns:
            str: AIåˆ†ææŠ¥å‘Š
        """
        if not DEEPSEEK_API_KEY or "sk-" not in DEEPSEEK_API_KEY:
            print("[Warning] æœªé…ç½® DEEPSEEK_API_KEYï¼Œè·³è¿‡ AI åˆ†æã€‚")
            return "æœªé…ç½® API Keyï¼Œæ— æ³•ç”Ÿæˆ AI æŠ¥å‘Šã€‚"
        
        # å‡†å¤‡AIä¸Šä¸‹æ–‡
        context = AIAnalyzer.prepare_ai_context(data, analysis_result)
        
        # æ„å»ºä¸“ä¸šæç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºä¸­å›½Aè‚¡å¸‚åœºè¯ç›‘ä¼šè¡Œä¸šåˆ†ç±»èµ„é‡‘æµå‘åˆ†æçš„èµ„æ·±é‡‘èåˆ†æå¸ˆã€‚
æˆ‘å°†ä¸ºä½ æä¾›æœ€æ–°çš„è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®ï¼ŒåŒ…å«3æ—¥ã€5æ—¥ã€10æ—¥å¤šæ—¶é—´ç»´åº¦çš„å®Œæ•´åˆ†æã€‚

{context}

è¯·æ ¹æ®æä¾›çš„æ•°æ®ç”Ÿæˆä¸€ä»½å…¨é¢çš„è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†ææŠ¥å‘Šï¼Œæ¶µç›–ä»¥ä¸‹æ–¹é¢ï¼š
ğŸ’° **èµ„é‡‘æµå‘è¶‹åŠ¿åˆ†æ**ï¼šåˆ†æ3æ—¥ã€5æ—¥ã€10æ—¥å‡€æµå…¥/å‡€æµå‡ºæƒ…å†µï¼Œåˆ¤æ–­çŸ­æœŸã€ä¸­æœŸã€é•¿æœŸèµ„é‡‘è¶‹åŠ¿  
ğŸ”¥ **è¡Œä¸šè½®åŠ¨åˆ†æ**ï¼šè¯†åˆ«çŸ­æœŸã€ä¸­æœŸã€é•¿æœŸå¼ºåŠ¿è¡Œä¸šï¼Œåˆ†æè¡Œä¸šè½®åŠ¨è§„å¾‹  
ğŸ“ˆ **è¡Œä¸šå¼ºåº¦æ’å**ï¼šåŸºäºå¤šæ—¶é—´ç»´åº¦ç»¼åˆè¯„åˆ†ï¼Œè¯†åˆ«æœ€å¼ºè¡Œä¸šå’Œæœ€å¼±è¡Œä¸š  
âš ï¸ **é£é™©è¡Œä¸šè­¦ç¤º**ï¼šå¯¹äºå¤§é¢æµå‡ºã€è´Ÿæµå…¥æµå‡ºæ¯”çš„è¡Œä¸šç»™å‡ºé£é™©æç¤º  
ğŸ¯ **æŠ•èµ„ç­–ç•¥å»ºè®®**ï¼šåŸºäºè¡Œä¸šèµ„é‡‘æµå‘åˆ†æï¼Œç»™å‡ºçŸ­çº¿ã€ä¸­é•¿çº¿çš„è¡Œä¸šæŠ•èµ„å»ºè®®  
ğŸ“Š **å¸‚åœºæƒ…ç»ªåˆ¤æ–­**ï¼šé€šè¿‡è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®åˆ¤æ–­å½“å‰å¸‚åœºæ•´ä½“æƒ…ç»ªå’Œè¡Œä¸šåå¥½  
ğŸŒŠ **è¡Œä¸šè½®åŠ¨æ´å¯Ÿ**ï¼šåˆ†æè¡Œä¸šè½®åŠ¨çš„çŸ­æœŸã€ä¸­æœŸã€é•¿æœŸé€»è¾‘

**é‡è¦è¦æ±‚**ï¼š
- è¯·ç›´æ¥è¾“å‡ºä¸­æ–‡æŠ¥å‘Šï¼Œç¡®ä¿åˆ†ææ·±å…¥ä¸”å…·æœ‰å®é™…æŒ‡å¯¼ä»·å€¼
- **ä¸è¦ä½¿ç”¨è¡¨æ ¼æ ¼å¼**ï¼Œä¿æŒæŠ¥å‘Šçš„ç®€æ´æ€§å’Œæ˜“è¯»æ€§
- **æŠ¥å‘Šå†…å®¹è¯·ä¸¥æ ¼æ§åˆ¶åœ¨3500å­—ä»¥å†…**
- é‡ç‚¹å…³æ³¨å¤šæ—¶é—´ç»´åº¦çš„å¯¹æ¯”åˆ†æå’Œè¡Œä¸šè½®åŠ¨è§„å¾‹
- ä½¿ç”¨Markdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°ï¼Œä¾¿äºé˜…è¯»
"""

        # ========== æ–°å¢ï¼šæ‰“å°å®Œæ•´æç¤ºè¯åŠŸèƒ½ ==========
        print("\n" + "="*80)
        print("ğŸš€ å‡†å¤‡å‘é€ç»™ DeepSeek API çš„å®Œæ•´æç¤ºè¯:")
        print("="*80)
        print("\nğŸ“‹ ã€ç³»ç»Ÿæç¤ºè¯ã€‘:")
        print("ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†æå¸ˆã€‚")
        print("\nğŸ“ ã€ç”¨æˆ·æç¤ºè¯ã€‘:")
        print(prompt)
        print("\n" + "="*80)
        print(f"ğŸ“Š ã€æç¤ºè¯ç»Ÿè®¡ä¿¡æ¯ã€‘:")
        print(f"   - æ€»å­—ç¬¦æ•°: {len(prompt):,} å­—ç¬¦")
        print(f"   - è¡Œæ•°: {len(prompt.split(chr(10)))} è¡Œ")
        print(f"   - é¢„è®¡ä»¤ç‰Œæ•°: ~{len(prompt.split()) * 1.3:.0f} tokens")
        print("="*80)
        
        print("\n=== å‘ DeepSeek API å‘é€è¯·æ±‚ ===")
        
        # ä½¿ç”¨requestsç›´æ¥è°ƒç”¨DeepSeek API
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Aè‚¡è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†æå¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            "stream": False
        }

        try:
            response = requests.post(
                f"{DEEPSEEK_BASE_URL}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    report = result['choices'][0]['message']['content']
                    return report
                else:
                    print(f"DeepSeek API è¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                    return "DeepSeek API è¿”å›æ ¼å¼å¼‚å¸¸"
            else:
                print(f"DeepSeek API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return f"DeepSeek API è¯·æ±‚å¤±è´¥: {response.status_code}"
                
        except Exception as e:
            print(f"è°ƒç”¨ DeepSeek API å‡ºé”™: {e}")
            return f"AI åˆ†æå¤±è´¥: {e}"

# =============================================================================
# æŠ¥å‘Šç”Ÿæˆæ¨¡å—
# =============================================================================

class ReportGenerator:
    """
    æŠ¥å‘Šç”Ÿæˆç±» - ä¸“æ³¨äºè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†ææŠ¥å‘Šç”Ÿæˆ
    """
    
    @staticmethod
    def generate_analysis_report(data, ai_report, filename=None):
        """
        ç”Ÿæˆè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†ææŠ¥å‘Šæ–‡ä»¶
        
        Args:
            data: åŸå§‹æ•°æ®
            ai_report: AIåˆ†ææŠ¥å‘Š
            filename: æ–‡ä»¶åï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶åï¼Œå¤±è´¥è¿”å›None
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"AIè¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†ææŠ¥å‘Š_{timestamp}.md"
        
        try:
            # è·å–å¸‚åœºæ¦‚å†µ
            summary = DataAnalyzer.get_industry_summary(data)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = f"""# è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†ææŠ¥å‘Š

## ğŸ“Š è¡Œä¸šæ•´ä½“æ¦‚å†µ
- **æ•°æ®è·å–æ—¶é—´**: {get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}
- **è¡Œä¸šæ€»æ•°**: {summary['total_industries']}ä¸ª
- **3æ—¥ä¸Šæ¶¨è¡Œä¸š**: {summary['positive_3d_count']}ä¸ª ({summary['positive_3d_count']/summary['total_industries']*100:.1f}%)
- **5æ—¥ä¸Šæ¶¨è¡Œä¸š**: {summary['positive_5d_count']}ä¸ª ({summary['positive_5d_count']/summary['total_industries']*100:.1f}%)
- **10æ—¥ä¸Šæ¶¨è¡Œä¸š**: {summary['positive_10d_count']}ä¸ª ({summary['positive_10d_count']/summary['total_industries']*100:.1f}%)
- **3æ—¥æ€»å‡€æµå…¥**: {summary['total_inflow_3d_billion']:.2f}äº¿å…ƒ
- **5æ—¥æ€»å‡€æµå…¥**: {summary['total_inflow_5d_billion']:.2f}äº¿å…ƒ
- **10æ—¥æ€»å‡€æµå…¥**: {summary['total_inflow_10d_billion']:.2f}äº¿å…ƒ
- **3æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”**: {summary['avg_ratio_3d']:.3f}
- **5æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”**: {summary['avg_ratio_5d']:.3f}
- **10æ—¥å¹³å‡æµå…¥æµå‡ºæ¯”**: {summary['avg_ratio_10d']:.3f}

## ğŸ’° å‡€æµå…¥å‰10è¡Œä¸šï¼ˆ3æ—¥ï¼‰
"""
            for i, stock in enumerate(summary['top_inflow_3d'], 1):
                report_content += f"{i}. **{stock['è¡Œä¸šåç§°']}**({stock['è¡Œä¸šä»£ç ']}) - å‡€æµå…¥: {stock['3æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ, æ¶¨è·Œå¹…: {stock['3æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%\n"
            
            report_content += f"""
## ğŸ’° å‡€æµå…¥å‰10è¡Œä¸šï¼ˆ5æ—¥ï¼‰
"""
            for i, stock in enumerate(summary['top_inflow_5d'], 1):
                report_content += f"{i}. **{stock['è¡Œä¸šåç§°']}**({stock['è¡Œä¸šä»£ç ']}) - å‡€æµå…¥: {stock['5æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ, æ¶¨è·Œå¹…: {stock['5æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%\n"
            
            report_content += f"""
## ğŸ’° å‡€æµå…¥å‰10è¡Œä¸šï¼ˆ10æ—¥ï¼‰
"""
            for i, stock in enumerate(summary['top_inflow_10d'], 1):
                report_content += f"{i}. **{stock['è¡Œä¸šåç§°']}**({stock['è¡Œä¸šä»£ç ']}) - å‡€æµå…¥: {stock['10æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ, æ¶¨è·Œå¹…: {stock['10æ—¥å¹³å‡æ¶¨è·Œå¹…']*100:.2f}%\n"
            
            report_content += f"""
## ğŸ¤– AIæ™ºèƒ½åˆ†ææŠ¥å‘Š

{ai_report}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}*
*æ•°æ®æ¥æº: æ–°æµªè´¢ç»è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®*
*åˆ†æå·¥å…·: DeepSeek AI*
"""
            
            # ä¿å­˜æŠ¥å‘Š
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"AIåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
            return filename
            
        except Exception as e:
            print(f"ç”Ÿæˆåˆ†ææŠ¥å‘Šå‡ºé”™: {str(e)}")
            return None

# =============================================================================
# æ¨é€åŠŸèƒ½æ¨¡å—
# =============================================================================

class PushNotifier:
    """
    æ¨é€é€šçŸ¥ç±» - ä¸“æ³¨äºå¾®ä¿¡æ¨é€åŠŸèƒ½
    """
    
    @staticmethod
    def send_push(title, content, url=None):
        """
        ä½¿ç”¨ WxPusher æ¨é€æ¶ˆæ¯
        
        Args:
            title: æ¨é€æ ‡é¢˜
            content: æ¨é€å†…å®¹
            url: æ¨é€é“¾æ¥
            
        Returns:
            bool: æ¨é€æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*20 + f" PUSH: {title} " + "="*20)
        print("æ­£åœ¨å‘é€ WxPusher æ¨é€...")
        print("="*50 + "\n")
        
        payload = {
            "appToken": WXPUSHER_APP_TOKEN,
            "content": content,
            "summary": title,
            "contentType": 3,  # 3 è¡¨ç¤º Markdown æ ¼å¼
            "topicIds": WXPUSHER_TOPIC_IDS,
            "url": url,
            "verifyPay": False,
            "selfUid": "",
            "showPushType": 1
        }

        try:
            response = requests.post(WXPUSHER_URL, 
                                   json=payload, 
                                   headers={'Content-Type': 'application/json'},
                                   timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 1000:
                    print("âœ… WxPusher æ¨é€æˆåŠŸ")
                    return True
                else:
                    print(f"âŒ WxPusher æ¨é€å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                    return False
            else:
                print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ æ¨é€è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return False
    
    @staticmethod
    def generate_push_content(summary, csv_file, ai_report, full_report=False):
        """
        ç”Ÿæˆæ¨é€å†…å®¹ï¼ˆåªæ¨é€AIåˆ†ææŠ¥å‘Šçš„markdownæ ¼å¼ï¼‰
        
        Args:
            summary: åˆ†ææ‘˜è¦æ•°æ®
            csv_file: CSVæ•°æ®æ–‡ä»¶è·¯å¾„
            ai_report: DeepSeekè¿”å›çš„AIåˆ†ææŠ¥å‘Šå†…å®¹
            full_report: æ˜¯å¦æ¨é€å®Œæ•´æŠ¥å‘Šå†…å®¹
            
        Returns:
            str: æ¨é€å†…å®¹
        """
        try:
            if ai_report:
                # ç›´æ¥ä½¿ç”¨AIæŠ¥å‘Šå†…å®¹ï¼ˆå·²æ§åˆ¶åœ¨3000å­—ä»¥å†…ï¼‰
                content = ai_report
                return content
            elif csv_file is not None:
                # å¦‚æœæœ‰CSVæ–‡ä»¶ä½†æ²¡æœ‰AIæŠ¥å‘Šï¼Œæ˜¾ç¤ºåŸºç¡€ä¿¡æ¯
                basic_content = f"""è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†ææŠ¥å‘Š

ğŸ“Š æ•°æ®æ¦‚å†µï¼š
- è¡Œä¸šæ€»æ•°: {summary.get('total_industries', 0)}ä¸ª
- 3æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_3d_billion', 0):.2f}äº¿å…ƒ  
- 5æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_5d_billion', 0):.2f}äº¿å…ƒ
- 10æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_10d_billion', 0):.2f}äº¿å…ƒ

ğŸ“ æ•°æ®æ–‡ä»¶ï¼š{os.path.basename(csv_file)}
ğŸ•’ ç”Ÿæˆæ—¶é—´ï¼š{get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}

âš ï¸ AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚"""
                return basic_content
            else:
                  # æ—¢æ²¡æœ‰AIæŠ¥å‘Šä¹Ÿæ²¡æœ‰CSVæ–‡ä»¶ï¼Œæ˜¾ç¤ºæœ€ç®€ä¿¡æ¯
                  minimal_content = f"""è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†ææŠ¥å‘Š

ğŸ“Š æ•°æ®æ¦‚å†µï¼š
- è¡Œä¸šæ€»æ•°: {summary.get('total_industries', 0)}ä¸ª
- 3æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_3d_billion', 0):.2f}äº¿å…ƒ  
- 5æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_5d_billion', 0):.2f}äº¿å…ƒ
- 10æ—¥æ€»å‡€æµå…¥: {summary.get('total_inflow_10d_billion', 0):.2f}äº¿å…ƒ

ğŸ•’ ç”Ÿæˆæ—¶é—´ï¼š{get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}

âš ï¸ AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚"""
                  return minimal_content
            
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆæ¨é€å†…å®¹å¤±è´¥: {str(e)}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„é”™è¯¯æç¤º
            error_content = f"""è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†ææŠ¥å‘Š

âš ï¸  å†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}

ğŸ•’ ç”Ÿæˆæ—¶é—´ï¼š{get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}"""
            return error_content
    
    @staticmethod
    def push_analysis_results(summary, csv_file, ai_report, push_enabled=True, full_report=False):
        """
        æ¨é€åˆ†æç»“æœ
        
        Args:
            summary: åˆ†ææ‘˜è¦æ•°æ®
            csv_file: CSVæ•°æ®æ–‡ä»¶è·¯å¾„
            ai_report: AIåˆ†ææŠ¥å‘Šå†…å®¹
            push_enabled: æ˜¯å¦å¯ç”¨æ¨é€
            full_report: æ˜¯å¦æ¨é€å®Œæ•´æŠ¥å‘Šå†…å®¹
        """
        if not push_enabled:
            print("ğŸ“± æ¨é€åŠŸèƒ½å·²ç¦ç”¨")
            return
        
        if not WXPUSHER_APP_TOKEN:
            print("âš ï¸  æœªé…ç½® WXPUSHER_APP_TOKENï¼Œè·³è¿‡æ¨é€")
            return
        
        try:
            # ç”Ÿæˆæ¨é€å†…å®¹
            title = f"AIè¡Œä¸šèµ„é‡‘æµå‘åˆ†æ - {get_beijing_time().strftime('%mæœˆ%dæ—¥')}"
            content = PushNotifier.generate_push_content(summary, csv_file, ai_report, full_report)
            
            # è®¾ç½®URL (å¦‚æœæ²¡æœ‰CSVæ–‡ä»¶åˆ™ä¸è®¾ç½®URL)
            url = f"file://{os.path.abspath(csv_file)}" if csv_file else None
            
            # å‘é€æ¨é€
            success = PushNotifier.send_push(title, content, url)
            
            if success:
                if full_report:
                    print("ğŸ‰ å®Œæ•´åˆ†ææŠ¥å‘Šæ¨é€å®Œæˆ")
                else:
                    print("ğŸ‰ åˆ†æç»“æœæ¨é€å®Œæˆ")
            else:
                print("âŒ åˆ†æç»“æœæ¨é€å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ æ¨é€è¿‡ç¨‹å‡ºé”™: {str(e)}")

# =============================================================================
# ä¸»ç¨‹åºæ¨¡å—
# =============================================================================

class CSRCIndustryAIAnalyzer:
    """
    è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†æå¸ˆ - ä¸»æ§åˆ¶å™¨
    æ•´åˆæ•°æ®è·å–ã€åˆ†æã€AIå¤„ç†å’Œæ¨é€åŠŸèƒ½
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.data_fetcher = DataFetcher()
        self.data_analyzer = DataAnalyzer()
        self.ai_analyzer = AIAnalyzer()
        self.report_generator = ReportGenerator()
        self.push_notifier = PushNotifier()
    
    def run_analysis(self, total_pages=8, page_size=20, push_enabled=True):
        """
        è¿è¡Œå®Œæ•´çš„è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘åˆ†ææµç¨‹
        
        Args:
            total_pages: è·å–çš„æ•°æ®é¡µæ•°
            page_size: æ¯é¡µæ•°æ®é‡
            push_enabled: æ˜¯å¦å¯ç”¨æ¨é€
            
        Returns:
            dict: åˆ†æç»“æœï¼ŒåŒ…å«æ–‡ä»¶è·¯å¾„ç­‰ä¿¡æ¯
        """
        results = {
            'data': None,
            'csv_file': None,
            'summary': None,
            'analysis_result': None,
            'ai_report': None,
            'report_file': None
        }
        
        print("=== è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘AIåˆ†æå¸ˆ ===")
        
        # 1. è·å–æ•°æ®ï¼ˆè·å–å®Œæ•´æ•°æ®ï¼‰
        print("\n=== ç¬¬ä¸€æ­¥ï¼šè·å–è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ® ===")
        results['data'] = self.data_fetcher.collect_batch_data(total_pages=total_pages, page_size=page_size)
        
        if not results['data']:
            print("âŒ è¡Œä¸šæ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åˆ†æ")
            return results
        
        # 2. åŸºç¡€è¡Œä¸šåˆ†æ
        print("\n=== ç¬¬äºŒæ­¥ï¼šåŸºç¡€è¡Œä¸šå¸‚åœºåˆ†æ ===")
        results['summary'] = self.data_analyzer.get_industry_summary(results['data'])
        self._print_summary(results['summary'])
        
        # 3. ç»“æ„åŒ–åˆ†æ
        print("\n=== ç¬¬ä¸‰æ­¥ï¼šæ·±åº¦è¡Œä¸šç»“æ„åŒ–åˆ†æ ===")
        results['analysis_result'] = self.data_analyzer.analyze_market_structure(results['data'])
        
        # 4. AIæ™ºèƒ½åˆ†æ
        print("\n=== ç¬¬å››æ­¥ï¼šAIæ™ºèƒ½è¡Œä¸šåˆ†æ ===")
        results['ai_report'] = self.ai_analyzer.call_ai_analysis(results['data'], results['analysis_result'])
        
        if results['ai_report'] and not results['ai_report'].startswith("æœªé…ç½®"):
            print("âœ… AIè¡Œä¸šåˆ†æå®Œæˆ")
            print("AIè¡Œä¸šåˆ†æç»“æœ:")
            print("-" * 50)
            print(results['ai_report'])
            print("-" * 50)
            
            print(f"\nğŸ‰ è¡Œä¸šåˆ†æå®Œæˆï¼")
            print(f"ğŸ“„ AIæŠ¥å‘Š: DeepSeekè¿”å›çš„markdownæ ¼å¼åˆ†ææŠ¥å‘Š")
            
            # 5. æ¨é€åˆ†æç»“æœï¼ˆæ¨é€AIæŠ¥å‘Šå†…å®¹ï¼‰
            if push_enabled:
                print("\n=== ç¬¬äº”æ­¥ï¼šæ¨é€DeepSeekåˆ†ææŠ¥å‘Š ===")
                self.push_notifier.push_analysis_results(
                    results['summary'], 
                    None,  # ä¸å†éœ€è¦CSVæ–‡ä»¶è·¯å¾„
                    results['ai_report'], 
                    push_enabled=True, 
                    full_report=True
                )
        else:
            print("âŒ AIè¡Œä¸šåˆ†æå¤±è´¥æˆ–æœªé…ç½®API")
        
        return results
    
    def _print_summary(self, summary):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("è¡Œä¸šå¸‚åœºæ¦‚å†µ:")
        for key, value in summary.items():
            if not key.startswith('top_inflow'):
                print(f"  {key}: {value}")
        
        print("\nå‡€æµå…¥å‰5è¡Œä¸šï¼ˆ3æ—¥ï¼‰:")
        for i, stock in enumerate(summary['top_inflow_3d'][:5], 1):
            print(f"  {i}. {stock['è¡Œä¸šåç§°']}({stock['è¡Œä¸šä»£ç ']}) - {stock['3æ—¥å‡€æµå…¥']/1e8:.2f}äº¿å…ƒ")

def main():
    """ä¸»å‡½æ•° - è¯ç›‘ä¼šè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®è·å–ä¸AIåˆ†æ"""
    analyzer = CSRCIndustryAIAnalyzer()
    
    # è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
    results = analyzer.run_analysis(
        total_pages=8,     # è·å–8é¡µå®Œæ•´æ•°æ®
        page_size=20,      # æ¯é¡µ20æ¡æ•°æ®
        push_enabled=True  # å¯ç”¨æ¨é€
    )
    
    return results

if __name__ == "__main__":
    main()